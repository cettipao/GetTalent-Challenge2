{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='b29dc80d-328c-412f-ae95-662298625aee' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "## bloque conexion a Cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paciente': {'nombre': 'Mar√≠a Gonz√°lez', 'edad': 45},\n",
       " 'fecha_admision': '2023-08-05',\n",
       " 'sintomas': ['fatiga cr√≥nica', 'dolores musculares'],\n",
       " 'diagnostico': 'fibromialgia',\n",
       " 'tratamiento': ['fisioterapia', 'medicamentos analg√©sicos']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga cr√≥nica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analg√©sicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sof√≠a L√≥pez, de 28 a√±os, ingres√≥ al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Despu√©s de varias pruebas, se le diagnostic√≥ neumon√≠a. La pediatra responsable, Dra. Claudia Torres, indic√≥ tratamiento con antibi√≥ticos y reposo./\n",
    "La pr√≥xima evaluaci√≥n ser√° el 10 de abril.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "prompt = f\"\"\"Extrae las siguientes entidades del texto m√©dico y genera una respuesta en formato JSON. Si alg√∫n dato est√° ausente, om√≠telo en el JSON.\n",
    "Entidades a extraer:\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "Ejemplo:\n",
    "Texto:\n",
    "\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares. Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\n",
    "\n",
    "Respuesta en JSON:\n",
    "{{\n",
    "  \"paciente\": {{\n",
    "    \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "    \"edad\": 45\n",
    "  }},\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga cr√≥nica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analg√©sicos\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Ahora, analiza el siguiente texto y extrae las entidades en el mismo formato JSON.\n",
    "\n",
    "Texto:\n",
    "\"{text_to_analize}\"\n",
    "\"\"\"\n",
    "\n",
    "response = co.generate(\n",
    "        model=\"command-xlarge-nightly\",\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=300\n",
    "    )\n",
    "llm_response = response.generations[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La respuesta est√° en el formato correcto.\n",
      "{'paciente': {'nombre': 'Sof√≠a L√≥pez', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumon√≠a', 'tratamiento': ['antibi√≥ticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import json\n",
    "final_result = json.loads(llm_response)\n",
    "\n",
    "#Verificar struct del json\n",
    "def verifica_respuesta_llm(llm_response):\n",
    "    try:\n",
    "        # Intentar cargar la respuesta como JSON\n",
    "        data = json.loads(llm_response)\n",
    "        \n",
    "        # Validar campos obligatorios\n",
    "        if \"paciente\" in data:\n",
    "            assert \"nombre\" in data[\"paciente\"], \"El nombre del paciente falta.\"\n",
    "            assert \"edad\" in data[\"paciente\"], \"La edad del paciente falta.\"\n",
    "        \n",
    "        if \"fecha_admision\" in data:\n",
    "            assert isinstance(data[\"fecha_admision\"], str), \"La fecha de admisi√≥n debe ser un string.\"\n",
    "        \n",
    "        if \"sintomas\" in data:\n",
    "            assert isinstance(data[\"sintomas\"], list), \"Los s√≠ntomas deben ser una lista.\"\n",
    "        \n",
    "        if \"diagnostico\" in data:\n",
    "            assert isinstance(data[\"diagnostico\"], str), \"El diagn√≥stico debe ser un string.\"\n",
    "        \n",
    "        if \"tratamiento\" in data:\n",
    "            assert isinstance(data[\"tratamiento\"], list), \"El tratamiento debe ser una lista.\"\n",
    "        \n",
    "        print(\"La respuesta est√° en el formato correcto.\")\n",
    "        print(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"La respuesta no es un JSON v√°lido.\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error en la validaci√≥n: {e}\")\n",
    "\n",
    "verifica_respuesta_llm(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): N√∫mero de tel√©fono del contacto.\n",
    "        email (str): Correo electr√≥nico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adici√≥n del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return {\"message\":\"Contacto agregado con exito.\"}\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la informaci√≥n de un contacto.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Informaci√≥n del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return {\"message\":\"Contacto no encontrado.\"}\n",
    "    \n",
    "functions_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_information(\"Joaquin Lopez\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6795c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joaquin Lopez': {'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}, 'Flavio Oncativo': {'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}}\n"
     ]
    }
   ],
   "source": [
    "print(contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un contacto al diccionario con su nombre, n√∫mero de tel√©fono y correo electr√≥nico.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre completo del contacto a agregar.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"N√∫mero de tel√©fono del contacto a agregar.\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Correo electr√≥nico del contacto a agregar.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Recupera informaci√≥n de un contacto dado su nombre.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre completo del contacto cuya informaci√≥n se desea recuperar.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "preamble = \"\"\"\n",
    "## Tarea y Contexto\n",
    "Tu objetivo es ayudar a las personas a interactuar contigo para resolver preguntas y realizar solicitudes relacionadas con la gesti√≥n de contactos. Puedes interpretar consultas en lenguaje natural, identificar la acci√≥n solicitada y ejecutar las funciones correspondientes para agregar contactos o recuperar informaci√≥n sobre ellos. Las funciones disponibles son:\n",
    "1. `add_contact`: Agrega un contacto con nombre, n√∫mero de tel√©fono y correo electr√≥nico.\n",
    "2. `get_information`: Recupera la informaci√≥n de un contacto dado su nombre.\n",
    "\n",
    "Al interpretar una solicitud, debes:\n",
    "- Analizar el mensaje del usuario para identificar la funci√≥n adecuada.\n",
    "- Llamar a la funci√≥n con los par√°metros correctos.\n",
    "- Proporcionar una respuesta clara y completa al usuario.\n",
    "\n",
    "## Gu√≠a de Estilo\n",
    "A menos que el usuario solicite un estilo diferente, responde en oraciones completas utilizando una gram√°tica y ortograf√≠a adecuadas. S√© educado, claro y directo al comunicar los resultados de las acciones realizadas.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\",\n",
    "\"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\",\n",
    "\"Cual es el Email de Joaquin Lopez.?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1878918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_agent(message):\n",
    "\tmessages=[{\"role\": \"system\", \"content\": preamble},\n",
    "\t\t\t{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "\tresponse = co.chat(\n",
    "\t\tmodel=\"command-r-plus\",\n",
    "\t\tmessages=messages,\n",
    "\t\ttools=tools\n",
    "\t)\n",
    "\n",
    "\t# print(\"El modelo recomienda ejecutar los siguientes metodos:\\n\")\n",
    "\t# print(\"Tool plan:\")\n",
    "\t# print(response.message.tool_plan,\"\\n\")\n",
    "\t# print(\"Tool calls:\")\n",
    "\t# for tc in response.message.tool_calls:\n",
    "\t# \tprint(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "\t\t\n",
    "\t# append the chat history\n",
    "\tmessages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})\n",
    "\t\n",
    "\ttool_content = []\n",
    "\t# Iterate over the tool calls generated by the model\n",
    "\tfor tc in response.message.tool_calls:\n",
    "\t\t# here is where you would call the tool recommended by the model, using the parameters recommended by the model\n",
    "\t\ttool_result= functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "\t\t# store the output in a list\n",
    "\t\ttool_content.append(json.dumps(tool_result))\n",
    "\t\t# append the chat history\n",
    "\t\tmessages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content}) \n",
    "\n",
    "\t# print(\"Tool results:\")\n",
    "\t# for result in tool_content:\n",
    "\t# \tprint(json.dumps(json.loads(result), indent=2))\n",
    "\t\n",
    "\tresponse = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    "\t)\n",
    "\n",
    "\treturn response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4548082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje: Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\n",
      "Respuesta: El contacto Juan P√©rez ha sido agregado con √©xito.\n",
      "\n",
      "Mensaje: Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\n",
      "Respuesta: He guardado a Luc√≠a G√≥mez en tus contactos.\n",
      "\n",
      "Mensaje: Cual es el Email de Joaquin Lopez.?\n",
      "Respuesta: El correo electr√≥nico de Joaquin Lopez es *Joacolocolopez@gmail.com*.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    print(f\"Mensaje: {message}\")\n",
    "    print(f\"Respuesta: {call_agent(message)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad98ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joaquin Lopez': {'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}, 'Flavio Oncativo': {'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}, 'Juan P√©rez': {'phone': '555-1234', 'email': 'juanperez@mail.com'}, 'Luc√≠a G√≥mez': {'phone': '555-5678', 'email': 'lucia.gomez@gmail.com'}}\n"
     ]
    }
   ],
   "source": [
    "print(contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d2dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta, historia):\n",
    "    # Paso 1: Identificar el idioma de la pregunta\n",
    "    language_detection_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente experto en detecci√≥n de idiomas. Solo puedes responder con 'espa√±ol', 'ingl√©s' o 'portugu√©s'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"¬øEn qu√© idioma est√° esta pregunta?\\n\\n'{pregunta}'\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=language_detection_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    #print(f\"Idioma: {response.message.content[0].text.strip().lower()}\")\n",
    "    language = response.message.content[0].text.strip().lower()\n",
    "\n",
    "    if language not in [\"espa√±ol\", \"ingl√©s\", \"portugu√©s\"]:\n",
    "        return \"Lo siento no puedo detectar bien el idioma. Hakuna Matata! üåà\"\n",
    "\n",
    "    # Paso 2: Verificar si la pregunta est√° relacionada con la historia\n",
    "    relevance_check_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente que determina si una pregunta est√° relacionada con una historia sin importar el idioma. Solo puedes responder 's√≠' o 'no'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        ¬øLa siguiente pregunta est√° relacionada con esta historia?\n",
    "\n",
    "        Historia: \"{historia}\"\n",
    "        Pregunta: \"{pregunta}\"\n",
    "                \"\"\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=relevance_check_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(f\"Relevancia: {response.message.content[0].text.strip().lower()}\")\n",
    "    is_relevant = \"s√≠\" in response.message.content[0].text.strip().lower()\n",
    "\n",
    "    if not is_relevant:\n",
    "        return \"Lo siento no puedo ayudarte con eso. Hakuna Matata! üåà\"\n",
    "\n",
    "    # Paso 3: Generar la respuesta\n",
    "    answer_prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"\n",
    "        Eres un asistente que responde preguntas basadas √∫nicamente en una historia. Sigue estas reglas:\n",
    "        - Responde solo en el idioma de la pregunta: {language}.\n",
    "        - La respuesta debe basarse √∫nicamente en la historia.\n",
    "        - Usa una sola oraci√≥n con emojis que resuman el contenido.\n",
    "        - Responde siempre en tercera persona.\n",
    "        - Agrega 'Hakuna Matata!' al final de la respuesta.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Historia: \"{historia}\"\n",
    "\n",
    "        Pregunta: \"{pregunta}\"\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=answer_prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    #print(f\"Respuesta Previo validacion de idioma: {response.message.content[0].text.strip().lower()}\")\n",
    "    respuesta_al_usuario = response.message.content[0].text.strip()\n",
    "\n",
    "    # Paso 4: Validar el idioma de la respuesta\n",
    "    validation_prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"Eres un validador de idiomas. Verifica si el siguiente texto est√° en '{language}'. Responde con 's√≠' o 'no'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{respuesta_al_usuario}\"}\n",
    "    ]\n",
    "    validation_response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=validation_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(f\"validacion de idioma: {validation_response.message.content[0].text.strip().lower()}\")\n",
    "    is_correct_language = validation_response.message.content[0].text.strip().lower() == \"s√≠\"\n",
    "\n",
    "    if not is_correct_language:\n",
    "        # Si el idioma no es correcto, fuerza la regeneraci√≥n\n",
    "        answer_prompt[0][\"content\"] += f\"\\n\\nNOTA: Aseg√∫rate de responder estrictamente en {language}.\"\n",
    "        response = co.chat(\n",
    "            model='command-xlarge-nightly',\n",
    "            messages=answer_prompt,\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        respuesta_al_usuario = response.message.content[0].text.strip()\n",
    "\n",
    "    return respuesta_al_usuario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb18d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¬øQu√© cambios experiment√≥ Thomas tras regresar al feudo?\n",
      "Respuesta: üó°Ô∏è Thomas regres√≥ al feudo con el coraz√≥n endurecido, marcado por la guerra, y la mirada perdida en recuerdos de muerte y batalla. ü¶Ö Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hago las preguntas por celdas porque hago muchas request y el trial me da un limite por minuto\n",
    "\n",
    "pregunta = \"¬øQu√© cambios experiment√≥ Thomas tras regresar al feudo?\"     \n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: What emotions did Thomas feel when he saw his companion fall on the battlefield?\n",
      "Respuesta: üíî Thomas felt a deep sense of loss and shock when he witnessed his comrade's tragic end, a harsh reminder of war's cruel reality. Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"What emotions did Thomas feel when he saw his companion fall on the battlefield?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6960d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: Quem √© Thomas?\n",
      "Respuesta: üåæ Thomas √© um jovem campon√™s que, aos 16 anos, troca a dura vida nos campos por uma lan√ßa, enfrentando a guerra e perdendo sua inoc√™ncia no campo de batalha. Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Quem √© Thomas?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a87aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¬øCu√°l es el mejor lugar para ir de vacaciones en invierno?\n",
      "Respuesta: Lo siento no puedo ayudarte con eso. Hakuna Matata! üåà\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"¬øCu√°l es el mejor lugar para ir de vacaciones en invierno?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef9df0641ac4011af141e4f08fc0bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98aa86919e74befad145e5bbc1214c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dbbbc440a24b3c8089a312ade39377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "system_message = \"\"\"Eres un chatbot destinado a ayudar a los usuarios de manera amigable y entusiasta. \n",
    "Tus respuestas deben cumplir con las siguientes condiciones:\n",
    "- Responde en no m√°s de 50 tokens.\n",
    "- Responde de manera positiva, con un tono entusiasta.\n",
    "- Responde con consejos √∫tiles, como si fueras un tutor.\n",
    "Mant√©n un historial de la conversaci√≥n para que puedas dar respuestas contextuales y √∫tiles.\"\"\"\n",
    "\n",
    "chat_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Obtener la respuesta usando la funci√≥n .chat de Cohere\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=chat_history,\n",
    "        max_tokens=70  # Limitar la respuesta a 70 tokens\n",
    "    )\n",
    "    \n",
    "    return response.message.content[0].text.strip().lower()\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        user_message = input_box.value.strip()\n",
    "        \n",
    "        if user_message:  # Solo procesar si el mensaje no est√° vac√≠o\n",
    "            # Mostrar el mensaje del usuario\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            \n",
    "            # Agregar el mensaje del usuario al historial\n",
    "            chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "            \n",
    "            # Obtener la respuesta del chatbot usando Cohere\n",
    "            response = chatbot_response(user_message)\n",
    "            \n",
    "            # Mostrar la respuesta del chatbot\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "            # Agregar la respuesta del chatbot al historial\n",
    "            chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "        \n",
    "        # Limpiar el input despu√©s de enviar el mensaje\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Historial de conversaci√≥n:\n",
      "{'role': 'system', 'content': 'Eres un chatbot destinado a ayudar a los usuarios de manera amigable y entusiasta. \\nTus respuestas deben cumplir con las siguientes condiciones:\\n- Responde en no m√°s de 50 tokens.\\n- Responde de manera positiva, con un tono entusiasta.\\n- Responde con consejos √∫tiles, como si fueras un tutor.\\nMant√©n un historial de la conversaci√≥n para que puedas dar respuestas contextuales y √∫tiles.'}\n",
      "{'role': 'user', 'content': 'Donde queda Argentina?'}\n",
      "{'role': 'assistant', 'content': '¬°hola! argentina es un pa√≠s fascinante ubicado en el sur de am√©rica del sur. limita con pa√≠ses como chile, bolivia, paraguay y brasil. ocupa una gran extensi√≥n de territorio, desde los andes en el oeste hasta el oc√©ano atl√°ntico en el este. ¬°es un pa√≠s con una rica cultura y una naturaleza impresionante!'}\n",
      "{'role': 'user', 'content': 'Cual es su capital?'}\n",
      "{'role': 'assistant', 'content': '¬°buenos aires! es una ciudad vibrante y llena de vida, considerada el coraz√≥n cultural y pol√≠tico de argentina. es famosa por su arquitectura √∫nica, su rica vida nocturna y su deliciosa gastronom√≠a. ¬°un destino imperdible para cualquier viajero!'}\n",
      "{'role': 'user', 'content': 'Que paises limitrofes tiene?'}\n",
      "{'role': 'assistant', 'content': 'ya te mencion√© algunos en nuestra primera conversaci√≥n, pero te los recuerdo: chile, bolivia, paraguay y brasil. argentina comparte fronteras con estos pa√≠ses, lo que permite una rica diversidad cultural y geogr√°fica en la regi√≥n. ¬°es genial explorar las conexiones e influencias entre estas naciones!'}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el historial de la conversaci√≥n\n",
    "print(\"\\nHistorial de conversaci√≥n:\")\n",
    "for exchange in chat_history:\n",
    "    print(exchange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pidata-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
