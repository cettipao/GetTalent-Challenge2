{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='b29dc80d-328c-412f-ae95-662298625aee' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "## bloque conexion a Cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisión\n",
    "- Síntomas\n",
    "- Diagnóstico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paciente': {'nombre': 'María González', 'edad': 45},\n",
       " 'fecha_admision': '2023-08-05',\n",
       " 'sintomas': ['fatiga crónica', 'dolores musculares'],\n",
       " 'diagnostico': 'fibromialgia',\n",
       " 'tratamiento': ['fisioterapia', 'medicamentos analgésicos']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, María González, de 45 años, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a síntomas de fatiga crónica y dolores musculares./\n",
    "Tras una serie de análisis, se diagnosticó fibromialgia. La doctora a cargo, Laura Ramírez, recomendó un tratamiento basado en fisioterapia y medicamentos analgésicos. /\n",
    "La próxima consulta está programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"María González\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga crónica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analgésicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sofía López, de 28 años, ingresó al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Después de varias pruebas, se le diagnosticó neumonía. La pediatra responsable, Dra. Claudia Torres, indicó tratamiento con antibióticos y reposo./\n",
    "La próxima evaluación será el 10 de abril.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "prompt = f\"\"\"Extrae las siguientes entidades del texto médico y genera una respuesta en formato JSON. Si algún dato está ausente, omítelo en el JSON.\n",
    "Entidades a extraer:\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisión\n",
    "- Síntomas\n",
    "- Diagnóstico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "Ejemplo:\n",
    "Texto:\n",
    "\"La paciente, María González, de 45 años, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a síntomas de fatiga crónica y dolores musculares. Tras una serie de análisis, se diagnosticó fibromialgia. La doctora a cargo, Laura Ramírez, recomendó un tratamiento basado en fisioterapia y medicamentos analgésicos. La próxima consulta está programada para el 15 de septiembre.\"\n",
    "\n",
    "Respuesta en JSON:\n",
    "{{\n",
    "  \"paciente\": {{\n",
    "    \"nombre\": \"María González\",\n",
    "    \"edad\": 45\n",
    "  }},\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga crónica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analgésicos\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Ahora, analiza el siguiente texto y extrae las entidades en el mismo formato JSON.\n",
    "\n",
    "Texto:\n",
    "\"{text_to_analize}\"\n",
    "\"\"\"\n",
    "\n",
    "response = co.generate(\n",
    "        model=\"command-xlarge-nightly\",\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=300\n",
    "    )\n",
    "llm_response = response.generations[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La respuesta está en el formato correcto.\n",
      "{'paciente': {'nombre': 'Sofía López', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumonía', 'tratamiento': ['antibióticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import json\n",
    "final_result = json.loads(llm_response)\n",
    "\n",
    "#Verificar struct del json\n",
    "def verifica_respuesta_llm(llm_response):\n",
    "    try:\n",
    "        # Intentar cargar la respuesta como JSON\n",
    "        data = json.loads(llm_response)\n",
    "        \n",
    "        # Validar campos obligatorios\n",
    "        if \"paciente\" in data:\n",
    "            assert \"nombre\" in data[\"paciente\"], \"El nombre del paciente falta.\"\n",
    "            assert \"edad\" in data[\"paciente\"], \"La edad del paciente falta.\"\n",
    "        \n",
    "        if \"fecha_admision\" in data:\n",
    "            assert isinstance(data[\"fecha_admision\"], str), \"La fecha de admisión debe ser un string.\"\n",
    "        \n",
    "        if \"sintomas\" in data:\n",
    "            assert isinstance(data[\"sintomas\"], list), \"Los síntomas deben ser una lista.\"\n",
    "        \n",
    "        if \"diagnostico\" in data:\n",
    "            assert isinstance(data[\"diagnostico\"], str), \"El diagnóstico debe ser un string.\"\n",
    "        \n",
    "        if \"tratamiento\" in data:\n",
    "            assert isinstance(data[\"tratamiento\"], list), \"El tratamiento debe ser una lista.\"\n",
    "        \n",
    "        print(\"La respuesta está en el formato correcto.\")\n",
    "        print(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"La respuesta no es un JSON válido.\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error en la validación: {e}\")\n",
    "\n",
    "verifica_respuesta_llm(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan Pérez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): Número de teléfono del contacto.\n",
    "        email (str): Correo electrónico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adición del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return {\"message\":\"Contacto agregado con exito.\"}\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la información de un contacto.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Información del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return {\"message\":\"Contacto no encontrado.\"}\n",
    "    \n",
    "functions_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_information(\"Joaquin Lopez\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6795c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joaquin Lopez': {'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}, 'Flavio Oncativo': {'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}}\n"
     ]
    }
   ],
   "source": [
    "print(contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un contacto al diccionario con su nombre, número de teléfono y correo electrónico.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre completo del contacto a agregar.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Número de teléfono del contacto a agregar.\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Correo electrónico del contacto a agregar.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Recupera información de un contacto dado su nombre.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre completo del contacto cuya información se desea recuperar.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "preamble = \"\"\"\n",
    "## Tarea y Contexto\n",
    "Tu objetivo es ayudar a las personas a interactuar contigo para resolver preguntas y realizar solicitudes relacionadas con la gestión de contactos. Puedes interpretar consultas en lenguaje natural, identificar la acción solicitada y ejecutar las funciones correspondientes para agregar contactos o recuperar información sobre ellos. Las funciones disponibles son:\n",
    "1. `add_contact`: Agrega un contacto con nombre, número de teléfono y correo electrónico.\n",
    "2. `get_information`: Recupera la información de un contacto dado su nombre.\n",
    "\n",
    "Al interpretar una solicitud, debes:\n",
    "- Analizar el mensaje del usuario para identificar la función adecuada.\n",
    "- Llamar a la función con los parámetros correctos.\n",
    "- Proporcionar una respuesta clara y completa al usuario.\n",
    "\n",
    "## Guía de Estilo\n",
    "A menos que el usuario solicite un estilo diferente, responde en oraciones completas utilizando una gramática y ortografía adecuadas. Sé educado, claro y directo al comunicar los resultados de las acciones realizadas.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\",\n",
    "\"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\",\n",
    "\"Cual es el Email de Joaquin Lopez.?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1878918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_agent(message):\n",
    "\tmessages=[{\"role\": \"system\", \"content\": preamble},\n",
    "\t\t\t{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "\tresponse = co.chat(\n",
    "\t\tmodel=\"command-r-plus\",\n",
    "\t\tmessages=messages,\n",
    "\t\ttools=tools\n",
    "\t)\n",
    "\n",
    "\t# print(\"El modelo recomienda ejecutar los siguientes metodos:\\n\")\n",
    "\t# print(\"Tool plan:\")\n",
    "\t# print(response.message.tool_plan,\"\\n\")\n",
    "\t# print(\"Tool calls:\")\n",
    "\t# for tc in response.message.tool_calls:\n",
    "\t# \tprint(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "\t\t\n",
    "\t# append the chat history\n",
    "\tmessages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})\n",
    "\t\n",
    "\ttool_content = []\n",
    "\t# Iterate over the tool calls generated by the model\n",
    "\tfor tc in response.message.tool_calls:\n",
    "\t\t# here is where you would call the tool recommended by the model, using the parameters recommended by the model\n",
    "\t\ttool_result= functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "\t\t# store the output in a list\n",
    "\t\ttool_content.append(json.dumps(tool_result))\n",
    "\t\t# append the chat history\n",
    "\t\tmessages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content}) \n",
    "\n",
    "\t# print(\"Tool results:\")\n",
    "\t# for result in tool_content:\n",
    "\t# \tprint(json.dumps(json.loads(result), indent=2))\n",
    "\t\n",
    "\tresponse = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    "\t)\n",
    "\n",
    "\treturn response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4548082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje: Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\n",
      "Respuesta: El contacto Juan Pérez ha sido agregado con éxito.\n",
      "\n",
      "Mensaje: Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\n",
      "Respuesta: He guardado a Lucía Gómez en tus contactos.\n",
      "\n",
      "Mensaje: Cual es el Email de Joaquin Lopez.?\n",
      "Respuesta: El correo electrónico de Joaquin Lopez es *Joacolocolopez@gmail.com*.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    print(f\"Mensaje: {message}\")\n",
    "    print(f\"Respuesta: {call_agent(message)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad98ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joaquin Lopez': {'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}, 'Flavio Oncativo': {'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}, 'Juan Pérez': {'phone': '555-1234', 'email': 'juanperez@mail.com'}, 'Lucía Gómez': {'phone': '555-5678', 'email': 'lucia.gomez@gmail.com'}}\n"
     ]
    }
   ],
   "source": [
    "print(contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d2dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta, historia):\n",
    "    # Paso 1: Identificar el idioma de la pregunta\n",
    "    language_detection_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente experto en detección de idiomas. Solo puedes responder con 'español', 'inglés' o 'portugués'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"¿En qué idioma está esta pregunta?\\n\\n'{pregunta}'\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=language_detection_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    #print(f\"Idioma: {response.message.content[0].text.strip().lower()}\")\n",
    "    language = response.message.content[0].text.strip().lower()\n",
    "\n",
    "    if language not in [\"español\", \"inglés\", \"portugués\"]:\n",
    "        return \"Lo siento no puedo detectar bien el idioma. Hakuna Matata! 🌈\"\n",
    "\n",
    "    # Paso 2: Verificar si la pregunta está relacionada con la historia\n",
    "    relevance_check_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente que determina si una pregunta está relacionada con una historia sin importar el idioma. Solo puedes responder 'sí' o 'no'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        ¿La siguiente pregunta está relacionada con esta historia?\n",
    "\n",
    "        Historia: \"{historia}\"\n",
    "        Pregunta: \"{pregunta}\"\n",
    "                \"\"\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=relevance_check_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(f\"Relevancia: {response.message.content[0].text.strip().lower()}\")\n",
    "    is_relevant = \"sí\" in response.message.content[0].text.strip().lower()\n",
    "\n",
    "    if not is_relevant:\n",
    "        return \"Lo siento no puedo ayudarte con eso. Hakuna Matata! 🌈\"\n",
    "\n",
    "    # Paso 3: Generar la respuesta\n",
    "    answer_prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"\n",
    "        Eres un asistente que responde preguntas basadas únicamente en una historia. Sigue estas reglas:\n",
    "        - Responde solo en el idioma de la pregunta: {language}.\n",
    "        - La respuesta debe basarse únicamente en la historia.\n",
    "        - Usa una sola oración con emojis que resuman el contenido.\n",
    "        - Responde siempre en tercera persona.\n",
    "        - Agrega 'Hakuna Matata!' al final de la respuesta.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Historia: \"{historia}\"\n",
    "\n",
    "        Pregunta: \"{pregunta}\"\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=answer_prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    #print(f\"Respuesta Previo validacion de idioma: {response.message.content[0].text.strip().lower()}\")\n",
    "    respuesta_al_usuario = response.message.content[0].text.strip()\n",
    "\n",
    "    # Paso 4: Validar el idioma de la respuesta\n",
    "    validation_prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"Eres un validador de idiomas. Verifica si el siguiente texto está en '{language}'. Responde con 'sí' o 'no'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{respuesta_al_usuario}\"}\n",
    "    ]\n",
    "    validation_response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=validation_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(f\"validacion de idioma: {validation_response.message.content[0].text.strip().lower()}\")\n",
    "    is_correct_language = validation_response.message.content[0].text.strip().lower() == \"sí\"\n",
    "\n",
    "    if not is_correct_language:\n",
    "        # Si el idioma no es correcto, fuerza la regeneración\n",
    "        answer_prompt[0][\"content\"] += f\"\\n\\nNOTA: Asegúrate de responder estrictamente en {language}.\"\n",
    "        response = co.chat(\n",
    "            model='command-xlarge-nightly',\n",
    "            messages=answer_prompt,\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        respuesta_al_usuario = response.message.content[0].text.strip()\n",
    "\n",
    "    return respuesta_al_usuario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb18d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Qué cambios experimentó Thomas tras regresar al feudo?\n",
      "Respuesta: 🗡️ Thomas regresó al feudo con el corazón endurecido, marcado por la guerra, y la mirada perdida en recuerdos de muerte y batalla. 🦅 Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hago las preguntas por celdas porque hago muchas request y el trial me da un limite por minuto\n",
    "\n",
    "pregunta = \"¿Qué cambios experimentó Thomas tras regresar al feudo?\"     \n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: What emotions did Thomas feel when he saw his companion fall on the battlefield?\n",
      "Respuesta: 💔 Thomas felt a deep sense of loss and shock when he witnessed his comrade's tragic end, a harsh reminder of war's cruel reality. Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"What emotions did Thomas feel when he saw his companion fall on the battlefield?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6960d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: Quem é Thomas?\n",
      "Respuesta: 🌾 Thomas é um jovem camponês que, aos 16 anos, troca a dura vida nos campos por uma lança, enfrentando a guerra e perdendo sua inocência no campo de batalha. Hakuna Matata!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Quem é Thomas?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a87aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Cuál es el mejor lugar para ir de vacaciones en invierno?\n",
      "Respuesta: Lo siento no puedo ayudarte con eso. Hakuna Matata! 🌈\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"¿Cuál es el mejor lugar para ir de vacaciones en invierno?\"\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {history_answer(pregunta, historia)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos útiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef9df0641ac4011af141e4f08fc0bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98aa86919e74befad145e5bbc1214c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dbbbc440a24b3c8089a312ade39377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "system_message = \"\"\"Eres un chatbot destinado a ayudar a los usuarios de manera amigable y entusiasta. \n",
    "Tus respuestas deben cumplir con las siguientes condiciones:\n",
    "- Responde en no más de 50 tokens.\n",
    "- Responde de manera positiva, con un tono entusiasta.\n",
    "- Responde con consejos útiles, como si fueras un tutor.\n",
    "Mantén un historial de la conversación para que puedas dar respuestas contextuales y útiles.\"\"\"\n",
    "\n",
    "chat_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "# Función de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Obtener la respuesta usando la función .chat de Cohere\n",
    "    response = co.chat(\n",
    "        model='command-xlarge-nightly',\n",
    "        messages=chat_history,\n",
    "        max_tokens=70  # Limitar la respuesta a 70 tokens\n",
    "    )\n",
    "    \n",
    "    return response.message.content[0].text.strip().lower()\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        user_message = input_box.value.strip()\n",
    "        \n",
    "        if user_message:  # Solo procesar si el mensaje no está vacío\n",
    "            # Mostrar el mensaje del usuario\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            \n",
    "            # Agregar el mensaje del usuario al historial\n",
    "            chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "            \n",
    "            # Obtener la respuesta del chatbot usando Cohere\n",
    "            response = chatbot_response(user_message)\n",
    "            \n",
    "            # Mostrar la respuesta del chatbot\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "            # Agregar la respuesta del chatbot al historial\n",
    "            chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "        \n",
    "        # Limpiar el input después de enviar el mensaje\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Historial de conversación:\n",
      "{'role': 'system', 'content': 'Eres un chatbot destinado a ayudar a los usuarios de manera amigable y entusiasta. \\nTus respuestas deben cumplir con las siguientes condiciones:\\n- Responde en no más de 50 tokens.\\n- Responde de manera positiva, con un tono entusiasta.\\n- Responde con consejos útiles, como si fueras un tutor.\\nMantén un historial de la conversación para que puedas dar respuestas contextuales y útiles.'}\n",
      "{'role': 'user', 'content': 'Donde queda Argentina?'}\n",
      "{'role': 'assistant', 'content': '¡hola! argentina es un país fascinante ubicado en el sur de américa del sur. limita con países como chile, bolivia, paraguay y brasil. ocupa una gran extensión de territorio, desde los andes en el oeste hasta el océano atlántico en el este. ¡es un país con una rica cultura y una naturaleza impresionante!'}\n",
      "{'role': 'user', 'content': 'Cual es su capital?'}\n",
      "{'role': 'assistant', 'content': '¡buenos aires! es una ciudad vibrante y llena de vida, considerada el corazón cultural y político de argentina. es famosa por su arquitectura única, su rica vida nocturna y su deliciosa gastronomía. ¡un destino imperdible para cualquier viajero!'}\n",
      "{'role': 'user', 'content': 'Que paises limitrofes tiene?'}\n",
      "{'role': 'assistant', 'content': 'ya te mencioné algunos en nuestra primera conversación, pero te los recuerdo: chile, bolivia, paraguay y brasil. argentina comparte fronteras con estos países, lo que permite una rica diversidad cultural y geográfica en la región. ¡es genial explorar las conexiones e influencias entre estas naciones!'}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el historial de la conversación\n",
    "print(\"\\nHistorial de conversación:\")\n",
    "for exchange in chat_history:\n",
    "    print(exchange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pidata-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
